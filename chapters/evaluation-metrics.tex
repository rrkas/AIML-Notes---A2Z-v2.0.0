\chapter{Evaluation Metrics/ Criterion/ Loss Function/ Cost Function}

\section*{Notation}
\begin{table}[h]
    \begin{tabular}{|c|l|}
        \hline
        
       $n$  & Number of records \\ 
       \hline
       
       $y$ & actual output (reference) \\ 
       \hline
       
       $\hat{y}$ & predicted output (hypothesis) \\ 
       \hline 
       
    \end{tabular}
\end{table}

\section*{Metrics VS Criterion}
\begin{table}[h]
    \centering
    \begin{tabular}{|p{2cm}|p{6cm}|p{6cm}|}
        \hline
        
        \textbf{Aspect} & \textbf{Evaluation Metrics} & \textbf{Loss Function (Criterion)} \\
        \hline
        
        \textbf{Purpose} & Measure model performance on test or validation data after training. & Quantify error between predicted and actual values to guide optimization during training. \\
        \hline
        
        \textbf{Usage} & Assess model generalization and overall performance. & Internally used by optimizer to update model parameters based on prediction errors. \\
        \hline
        
        \textbf{Focus} & Reflects how well the model generalizes to new, unseen data. & Minimizing error on training data to improve model accuracy. \\
        \hline

        \textbf{Examples} & Accuracy, precision, recall, F1-score for classification tasks; RMSE, MAE for regression tasks. & MSE (Mean Squared Error), cross-entropy loss for classification tasks, etc. \\
        \hline
    \end{tabular}
\end{table}

Essentially, formulas are \textbf{same}.

\begin{table}[h]
    \begin{tabular}{l l}
        \textbf{Loss Function/ Cost Function/ Criterion} & Used in \textbf{training} phase \\
        
        \textbf{Evaluation Metrics} & Used in \textbf{testing} phase \\
    \end{tabular}
\end{table}


\section{Mean Absolute Difference (MAD)/ Mean Absolute Error (MAE)}\label{Mean Absolute Difference (MAD)}\label{Mean Absolute Error (MAE)}

\[
    MAD = MAE = \displaystyle\frac{1}{n} \cdot \sum_{i=1}^{n} \left| y_i - \hat{y}_i \right|
\]


\section{Mean Square Error (MSE)}\label{Mean Square Error (MSE)}
\[
    MSE = \displaystyle\frac{1}{n} \cdot \sum_{i=1}^{n} ( y_i - \hat{y}_i )^2
\]

\section{Root Mean Square Error (RMSE)}\label{Root Mean Square Error (RMSE)}
\[
    RMSE = \sqrt{MSE} = \displaystyle\sqrt{\frac{1}{n} \cdot \sum_{i=1}^{n} ( y_i - \hat{y}_i )^2}
\]


\section{Confusion Matrix}
\subsection{Accuracy}

\subsection{Precision}
\begin{itemize}
    \item What fraction of the returned results are relevant to the information need? \cite{ir-1}
\end{itemize}

\subsection{Recall}
\begin{itemize}
    \item What fraction of the relevant documents in the collection were returned by the system? \cite{ir-1}
\end{itemize}

\subsection{F-Score}


\section{Mean Average precision (mAP)}\label{Mean Average precision (mAP)}


















































